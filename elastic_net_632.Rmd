---
title: "Model Comparison using 632 Bootstrap Cross Validation"
author: "Adeline Shin"
date: "4/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(tidyverse)
library(caret)
library(ModelMetrics)
library(glmnet)
library(bootstrap)
```

# Loading the Data
```{r}
training_data = read_csv("./training_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  )

test_data = read_csv("./test_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  )

y = training_data$lbdldl
x = model.matrix(lbdldl ~ ., training_data)[, -(1:2)]
y_test = test_data$lbdldl
x_test = model.matrix(lbdldl ~ ., test_data)[, -(1:2)]
```

# Linear Model as Baseline
```{r}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

linear_fit = train(lbdldl ~ .,
                   data = training_data,
                   method = "lm",
                   trControl = ctrl1)

linear_coef = summary(linear_fit)
```

## Prediction using Linear Model
```{r}
lm_prediction = predict(linear_fit, newdata = test_data)
lm_mse = mse(y_test, lm_prediction)
```


# Ridge Regression Model
```{r}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

ridge_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0, 
                                         lambda = exp(seq(-0, 5, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(ridge_fit, main = "RMSE vs. Lambda for Ridge Regression")

ridge_coef = coef(ridge_fit$finalModel, ridge_fit$bestTune$lambda)
ridge_coef_sum = sum(as.vector(ridge_coef) != 0)
```

As shown on the graph above, the value of lambda that gives the lowest RMSE value is `r ridge_fit$bestTune$lambda`. The ridge model at this value of lambda gives `r ridge_coef_sum - 1` variables in the final model, which can then be used to predict cholesterol levels.

## Prediction using Ridge Model
```{r}
ridge_prediction = predict(ridge_fit, newdata = test_data)
ridge_mse = mse(y_test, ridge_prediction)
```

The ridge model gives an MSE of `r ridge_mse`, which is quite high, but that is because the lowest RMSE value is high as well. 

# Lasso Model
```{r}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

lasso_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(-1, 2, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(lasso_fit, main = "RMSE vs. Lambda for Lasso Regression")

lasso_coef = coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)
lasso_coef_sum = sum(as.vector(lasso_coef) != 0)
```

As shown on the graph above, the value of lambda that gives the lowest RMSE value is `r lasso_fit$bestTune$lambda`. The lasso model at this value of lambda gives `r lasso_coef_sum - 1` variables in the final model, which can then be used to predict cholesterol levels.

## Prediction using Lasso Model
```{r}
lasso_prediction = predict(lasso_fit, newdata = test_data)
lasso_mse = mse(y_test, lasso_prediction)
```

The lasso model gives an MSE of `r lasso_mse`. 

# Elastic Net Model
```{r}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

elastic_net_fit = train(lbdldl ~ .,
                        data = training_data,
                        method = "glmnet",
                        tuneGrid = expand.grid(alpha = 0.75, 
                                          lambda = exp(seq(-0, 2, length=100))),
                        preProc = c("center", "scale"),
                        trControl = ctrl1)

plot(elastic_net_fit, main = "RMSE vs. Lambda for Elastic Net")

elastic_net_coef = coef(elastic_net_fit$finalModel, elastic_net_fit$bestTune$lambda)
elastic_coef_sum = sum(as.vector(elastic_net_coef) != 0)
```

As shown in the graph above, the elastic net model with an alpha of 0.75 has the lowest RMSE at a lambda value of `r elastic_net_fit$bestTune$lambda`. This combination of alpha and beta gives a model that contains `r elastic_coef_sum - 1` predictors in the final model. This model is then used to predict the cholesterol level and compared to the test data.

## Prediction using Elastic Net 
```{r}
elastic_prediction = predict(elastic_net_fit, newdata = test_data)
elastic_mse = mse(y_test, elastic_prediction)
```

Prediction of cholesterol levels using the elastic net model gives an MSE of `r elastic_mse`. 

# Model Comparison
```{r}
resamp = resamples(list(lm = linear_fit,
                        ridge = ridge_fit,
                        lasso = lasso_fit,
                        elastic = elastic_net_fit))

resamp_summary = summary(resamp)

parallelplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "RMSE", main = "RMSE comparison of 4 Models")
```

As shown in the box plot above, the model created using ridge regression gives the lowest RMSE among the four models created for the purpose of predicting cholesterol levels. Therefore, the ridge regression model should be chosen when using 632 bootstrap as the cross validation method. 