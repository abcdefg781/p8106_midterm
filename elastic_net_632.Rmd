---
title: "Model Comparison in Predicting Cholesterol Levels"
subtitle: "P8106 Midterm Project"
author: "Adeline Shin, Group Members: Sabrina Lin and Ngoc Duong"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 4, 
  fig.height = 3,
  out.width = "90%"
)
options(warn = -1)
library(tidyverse)
library(caret)
library(ModelMetrics)
library(glmnet)
library(bootstrap)
```

# Introduction
In the US, high cholesterol is a common health problem, affecting more than 12% of adults over the age of 20, according to the CDC. This data on cholesterol was collected as a part of the NHANES database, which consists of answers to a national survey conducted on nutrition and health behavior among Americans.

Our group used the NHANES data to predict cholesterol based on demographic, dietary, laboratory, and questionnaire data from the surveys conducted during 2015-2016. We picked a combination of 63 potential predictors from these categories in order to cover potential social, behavioral, and genetic determinants of the outcome variable, LDL cholesterol levels. We were interested in determining which model type was the most effective in predicting cholesterol levels given values for all other predictors.

The 63 variables as potential predictors were chosen by looking at the entirety of the NHANES dataset. Based on our research on causes of high cholesterol levels, we decided to pick variables across all sections of the NHANES dataset. The chosen variables are listed in Appendix A1, along with their variables names and categories.

Using these 63 variables, we first separated the data into training and test data using an 80/20 split. The training data was used to generate the models, and the test data was used to compare to the predicted values from the models. Using the RMSE calculated between the test data and the predicted data, we were able to compare which method had the lowest RMSE value, and therefore the best predictive abilities. 

# Exploratory Analysis and Visualization
In order to conduct a preliminary exploratory analysis, the dataset was loaded using the nhanesA package, then the summary() and table() functions were used to find potential outliers or data that was coded differently than expected. 

During this procedure, we found many missing values or unknown values that were coded with the values "7, 9, 777, 999, 777777, 999999, and ." in particular cases. These values were all converted to NAs for the purpose of this project, since we were not attempting to recover or predict missing data. We also noticed that some of the variables were separated into two categories for youth and adult, so we decided to just focus on adults for the scope of the project.

After filtering out all of the rows with NAs and using only rows with data from adults, a dataframe of 661 observations was left. 

# Models
In this project, the caret package in R was used to train all the models, and thus, the models compared were a linear model, a ridge regression model, a lasso model, and an elastic net model with an alpha value of 0.75. Our group members decided to use different cross-validation methods in order to see whether that would make a difference in terms of the final chosen model. In the models below, the 632 bootstrap cross-validation method was used, while other team members chose to use Monte Carlo cross-validation or leave one out cross-validation.

```{r include = FALSE}
# Loading the Data
training_data = read_csv("./training_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  ) %>% 
  select(-hiq011)

test_data = read_csv("./test_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  ) %>% 
  select(-hiq011)

# Creating x and y Variables for Test and Training Data
y = training_data$lbdldl
x = model.matrix(lbdldl ~ ., training_data)[, -(1:2)]
y_test = test_data$lbdldl
x_test = model.matrix(lbdldl ~ ., test_data)[, -(1:2)]
```

## Linear Model
```{r echo = FALSE}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

linear_fit = train(lbdldl ~ .,
                   data = training_data,
                   method = "lm",
                   trControl = ctrl1)

linear_coef = summary(linear_fit)

lm_prediction = predict(linear_fit, newdata = test_data)
lm_mse = mse(y_test, lm_prediction)
```

At a 95% significance level, only 6 of the 63 predictors are significant, which likely means that the model does not fit the data well. In addition, from the model summary, the adjusted R-squared value is only 0.1146, which confirms that the model is not a good fit for the data and therefore will likely not predict well. The linear model has a cross-validated MSE of `r lm_mse`, which is high, but expected, as the model itself did not have many significant variables.

## Ridge Regression Model
```{r echo = FALSE}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

ridge_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0, 
                                         lambda = exp(seq(-0, 5, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(ridge_fit, main = "RMSE vs. Lambda for Ridge Regression")

ridge_coef = coef(ridge_fit$finalModel, ridge_fit$bestTune$lambda)
ridge_coef_sum = sum(as.vector(ridge_coef) != 0)

# Prediction
ridge_prediction = predict(ridge_fit, newdata = test_data)
ridge_mse = mse(y_test, ridge_prediction)
```

As shown on the graph above, the value of lambda that gives the lowest RMSE value is `r ridge_fit$bestTune$lambda`. The ridge model at this value of lambda gives `r ridge_coef_sum - 1` predictors in the final model, including the different factor levels, which can then be used to predict cholesterol levels. The ridge model gives a cross-validated MSE of `r ridge_mse`, which is lower than that of the linear model.

## Lasso Model
```{r echo = FALSE}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

lasso_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(-1, 2, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(lasso_fit, main = "RMSE vs. Lambda for Lasso Regression")

lasso_coef = coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)
lasso_coef_sum = sum(as.vector(lasso_coef) != 0)

# Prediction
lasso_prediction = predict(lasso_fit, newdata = test_data)
lasso_mse = mse(y_test, lasso_prediction)
```

As shown on the graph above, the value of lambda that gives the lowest RMSE value is `r lasso_fit$bestTune$lambda`. The lasso model at this value of lambda gives `r lasso_coef_sum - 1` variables in the final model, which can then be used to predict cholesterol levels. With this value of lambda, the lasso model gives a cross-validated MSE of `r lasso_mse`. 

## Elastic Net Model
```{r echo = FALSE}
set.seed(13)
ctrl1 = trainControl(method = "boot632")

elastic_net_fit = train(lbdldl ~ .,
                        data = training_data,
                        method = "glmnet",
                        tuneGrid = expand.grid(alpha = 0.75, 
                                          lambda = exp(seq(-0, 2, length=100))),
                        preProc = c("center", "scale"),
                        trControl = ctrl1)

plot(elastic_net_fit, main = "RMSE vs. Lambda for Elastic Net")

elastic_net_coef = coef(elastic_net_fit$finalModel, elastic_net_fit$bestTune$lambda)
elastic_coef_sum = sum(as.vector(elastic_net_coef) != 0)

# Prediction
elastic_prediction = predict(elastic_net_fit, newdata = test_data)
elastic_mse = mse(y_test, elastic_prediction)
```

As shown in the graph above, the elastic net model with an alpha of 0.75 has the lowest RMSE at a lambda value of `r elastic_net_fit$bestTune$lambda`. This combination of alpha and beta gives a model that contains `r elastic_coef_sum - 1` predictors in the final model. This model is then used to predict the cholesterol level and compared to the test data. Prediction of cholesterol levels using the elastic net model gives a cross-validated MSE of `r elastic_mse`. 

## Model Comparison
```{r echo = FALSE}
resamp = resamples(list(lm = linear_fit,
                        ridge = ridge_fit,
                        lasso = lasso_fit,
                        elastic = elastic_net_fit))

resamp_summary = summary(resamp)

bwplot(resamp, metric = "RMSE", main = "RMSE comparison of 4 Models")
```

The box plot shows that the model created using the elastic net gives the lowest RMSE among the four models created for the purpose of predicting cholesterol levels. Therefore, the elastic model should be chosen when using 632 bootstrap as the cross validation method to predict cholesterol levels.

# Conclusion
All three of our group members used different forms of cross-validation for our model training, which resulted in different conclusions of which model did the best in predicting cholesterol levels. For 632 bootstrap and Monte Carlo cross-validation methods, elastic net proved to have the best model, but for LOOCV, the lasso model was best at prediction. Therefore, it is extremely important to specify model parameters, including cross-validation technique, when determining which model will work best in predicting outcomes.

While the elastic net model worked best with the 632 bootstrap cross-validation method, none of the models gave great results. The R-squared values for the models were all under 0.2, suggesting that none of the models created fit the data well, and therefore were not expected to predict cholesterol levels well. This is likely because we were dealing with real data with limited predictors, and the NHANES dataset did not necessarily capture all the predictors of high cholesterol level. In addition, given  more time, there could have been other model methods used to capture the data better, but those were not in the scope of this class so far.

# Appendices
## A1
Table of Predictors and Corresponding Variable Names
```{r echo = FALSE}
variable_df = tibble(
  variable = colnames(training_data[, -1]),
  definition = c("Respondent Sequence Number", "LDL/Triglyceride Levels (Outcome)", 
                "Albumin (ug/mL)", "Creatinine (mg/dL)", "Alkaline Phosphotase (IU/L)",
                "Bicarbonate (mmol/L)", "Glucose (mg/dL)", "Gamma Glutamyl Transferase (U/L)",
                "Lactate Dehydrogenase (U/L)", "Phosphorus (mg/dL)", "Potassium (mmol/L)", 
                "Total Bilirubin (mg/dL)", "Uric acid (mg/dL)", "Lymphocyte percent (%)",
                "Monocyte percent (%)", "Segmented neutrophils percent (%)", "Hemoglobin (g/dL)",
                "Hematocrit (%)", "High-Sensitivity C-Reactive Protein (hs-CRP) (mg/L)", 
                "Body Mass Index (kg/m**2)", "Waist Circumference (cm)", 
                "Systolic: Blood pressure", "Diastolic: Blood pressure", 
                "How often do you add ordinary salt to your food at the table?", 
                "How often is ordinary salt or seasoned salt added in cooking or preparing foods in your household?", 
                "Are you currently on any kind of diet?", 
                "Total number of foods/beverages reported in the individual foods file", 
                "Energy (kcal)", "Protein (gm)", "Carbohydrate (gm)", "Total sugars (gm)",
                "Dietary fiber (gm)", "Total fat (gm)", "Caffeine (mg)", "Alcohol (gm)", 
                "Was the amount of food that you ate yesterday much more than usual, usual, or much less than usual?", 
                "Total plain water drank yesterday", 
                "During the past 30 days did you eat any types of shellfish?", 
                "During the past 30 days did you eat any types of fish?", 
                "Total # of Dietary Supplements Taken", "Total # of Antacids Taken", 
                "Money Spent at Grocery Stores in the Last 30 Days", 
                "Money Spent on Eating Out in the Last 30 Days", 
                "Money Spent on Takeout in the Last 30 Days", "Number of Meals Ordered", 
                "Have you ever been told by a doctor or other health professional that you had hypertension?",
                "Ever had any pain or discomfort in chest", "General Health Level", 
                "Ever told that you had Diabetes", "How healthy is overall diet?", 
                "Worried food would run out", "Can't afford to eat balanced meals", 
                "Household food security", "Does the insurance plan cover prescription medicine?",
                "Do you get regular physical activity?", "Smoked 100 cigarettes in lifetime", 
                "Gender", "Age", "Education", "Recorded Race Hispanic Origin", 
                "Recorded Race with Non-Hispanic Asian Category", "Born in the US or not", 
                "Ratio of Family Income to Poverty")
)

knitr::kable(variable_df)
```

