---
title: "stl2137_nhanes_model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nhanesA)
library(tidyverse)
library(caret)
library(ModelMetrics)
set.seed(13)
```

# Data & Modeling Prep

### Read/Load in Data

```{r}
train_dat <- read_csv("./training_data_final.csv") %>% 
  mutate(
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    ds1dscnt = as.factor(ds1dscnt),
    ds1ancnt = as.factor(ds1ancnt)
  )

test_dat <- read_csv("./test_data_final.csv") %>% 
  mutate(
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    ds1dscnt = as.factor(ds1dscnt),
    ds1ancnt = as.factor(ds1ancnt)
  )

y_train = train_dat$lbdldl
x_train = model.matrix(lbdldl ~ ., train_dat)[, -(1:2)]


y_test = test_dat$lbdldl
x_test = model.matrix(lbdldl ~ ., test_dat)[, -(1:2)]

# creating training controls for 10-fold CV
control1 <- trainControl(method = "cv", number = 10)


```

### Writing functions for models using 10-fold CV 

```{r}
### Function to run model

k_fold_function <- function(method_sel, alpha_sel, lower_bound, upper_bound){
  model_fit <- train(x_train, y_train,
                   method = method_sel,
                   tuneGrid = expand.grid(alpha = alpha_sel, 
                                          lambda = exp(seq(lower_bound, upper_bound, length = 100))),
                   preProc = c("center", "scale"),
                   trControl = control1
)
  return(model_fit)
}

### Function to plot

plot_k_fold_function <- function(model_fit){
  model_plot <- plot(model_fit, xTrans = function(x_train) log(x_train))
  return(model_plot)
}


```


```{r}
lasso_fit <- k_fold_function("glmnet", 1, -1, 1)

lasso_plot <- plot_k_fold_function(lasso_fit)
```


# Pre Function Work 

### LASSO using 10-fold CV 

```{r}

plot(lasso_fit, xTrans = function(x_train) log(x_train))

lasso_fit$bestTune$lambda

coef_estimates <- coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)
num_coef <- sum(as.vector(coef_estimates) != 0)
```

### Predicting Lasso using 10-fold CV

```{r}
predict_lasso_fit <- predict(lasso_fit, newdata = test_dat)
lasso_mse <- mse(y_test, predict_lasso_fit)
```

Using a $\lambda$ of `r lasso_fit$bestTune$lambda`, the MSE of the lasso regression on the test data is `r lasso_mse`. There are `r num_coef` non-zero coefficient estimates.

### Lasso Using Leave One Out CV 

```{r}
# creating training controls for Leave One Out CV
control2 <- trainControl(method = "LOOCV")

lasso_loocv <- train(x_train, y_train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha=1, 
                                          lambda = exp(seq(0, 1, length = 100))),
                   preProc = c("center", "scale"),
                   trControl = control2
)

plot(lasso_loocv, xTrans = function(x_train) log(x_train))

lasso_loocv$bestTune$lambda

coef_estimates_loocv <- coef(lasso_loocv$finalModel, lasso_loocv$bestTune$lambda)
num_coef_loocv <- sum(as.vector(coef_estimates_loocv) != 0)
```

### Predict Lasso with LOOCV 
```{r}
predict_lasso_loocv <- predict(lasso_loocv, newdata = test_dat)
lasso_loocv_mse <- mse(y_test, predict_lasso_loocv)
```

Using a $\lambda$ of `r lasso_loocv$bestTune$lambda`, the MSE of the lasso regression on the test data is `r lasso_loocv_mse`. There are `r num_coef_loocv` non-zero coefficient estimates.

### Comparing models based off their CV stats

```{r}
resampled_lasso <- resamples(list(k_fold = lasso_fit, loocv = lasso_loocv))

resamp <- resamples(list(lm = lmFit, knn = knnFit))
summary(resamp)
```

