---
title: "Model Comparison in Predicting Cholesterol Levels"
subtitle: "P8106 Midterm Project"
author: "Adeline Shin (as5951)"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 4, 
  fig.height = 3,
  out.width = "90%"
)
options(warn = -1)
library(tidyverse)
library(caret)
library(ModelMetrics)
library(glmnet)
library(bootstrap)
```

# Results and Analysis
```{r include = FALSE}
# Loading the Data
training_data = read_csv("./training_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  )

test_data = read_csv("./test_data_final.csv") %>% 
  mutate(
    dbd100 = as.factor(dbd100),
    drqsprep = as.factor(drqsprep),
    drqsdiet = as.factor(drqsdiet),
    dr1_300 = as.factor(dr1_300),
    drd340 = as.factor(drd340),
    drd360 = as.factor(drd360),
    bpq020 = as.factor(bpq020),
    cdq001 = as.factor(cdq001),
    hsd010 = as.factor(hsd010),
    diq010 = as.factor(diq010),
    dbq700 = as.factor(dbq700),
    fsd032a = as.factor(fsd032a),
    fsd032c = as.factor(fsd032c),
    fsdhh = as.factor(fsdhh),
    hiq270 = as.factor(hiq270),
    paq605 = as.factor(paq605),
    smq020 = as.factor(smq020),
    riagendr = as.factor(riagendr),
    ridreth1 = as.factor(ridreth1),
    ridreth3 = as.factor(ridreth3),
    dmdborn4 = as.factor(dmdborn4)
  )

# Creating x and y Variables for Test and Training Data
y = training_data$lbdldl
x = model.matrix(lbdldl ~ ., training_data)[, -(1:2)]
y_test = test_data$lbdldl
x_test = model.matrix(lbdldl ~ ., test_data)[, -(1:2)]
```

## Linear Model
```{r echo = FALSE}
set.seed(13)
ctrl1 = trainControl(method = "cv", number = 10)

linear_fit = train(lbdldl ~ .,
                   data = training_data,
                   method = "lm",
                   trControl = ctrl1)

summary(linear_fit)

lm_prediction = predict(linear_fit, newdata = test_data)
lm_mse = mse(y_test, lm_prediction)
```


## Ridge Regression Model
```{r echo = FALSE}
set.seed(13)

ridge_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0, 
                                         lambda = exp(seq(-0, 5, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(ridge_fit, main = "RMSE vs. Lambda for Ridge Regression")

ridge_coef = coef(ridge_fit$finalModel, ridge_fit$bestTune$lambda)
ridge_coef_sum = sum(as.vector(ridge_coef) != 0)

# Prediction
ridge_prediction = predict(ridge_fit, newdata = test_data)
ridge_mse = mse(y_test, ridge_prediction)
```


## Lasso Model
```{r echo = FALSE}
set.seed(13)

lasso_fit = train(lbdldl ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(-1, 2, length=100))),
                  preProc = c("center", "scale"),
                  trControl = ctrl1)

plot(lasso_fit, main = "RMSE vs. Lambda for Lasso Regression")

lasso_coef = coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)
lasso_coef_sum = sum(as.vector(lasso_coef) != 0)

# Prediction
lasso_prediction = predict(lasso_fit, newdata = test_data)
lasso_mse = mse(y_test, lasso_prediction)
```

As shown on the graph above, the value of lambda that gives the lowest RMSE value is `r lasso_fit$bestTune$lambda`. The lasso model at this value of lambda gives `r lasso_coef_sum - 1` variables in the final model, which can then be used to predict cholesterol levels. With this value of lambda, the lasso model gives an MSE of `r lasso_mse`. 

## Elastic Net Model
```{r echo = FALSE}
set.seed(13)

elastic_net_fit = train(lbdldl ~ .,
                        data = training_data,
                        method = "glmnet",
                        tuneGrid = expand.grid(alpha = 0.75, 
                                          lambda = exp(seq(-0, 2, length=100))),
                        preProc = c("center", "scale"),
                        trControl = ctrl1)

plot(elastic_net_fit, main = "RMSE vs. Lambda for Elastic Net")

elastic_net_coef = coef(elastic_net_fit$finalModel, elastic_net_fit$bestTune$lambda)
elastic_coef_sum = sum(as.vector(elastic_net_coef) != 0)

# Prediction
elastic_prediction = predict(elastic_net_fit, newdata = test_data)
elastic_mse = mse(y_test, elastic_prediction)
```

As shown in the graph above, the elastic net model with an alpha of 0.75 has the lowest RMSE at a lambda value of `r elastic_net_fit$bestTune$lambda`. This combination of alpha and beta gives a model that contains `r elastic_coef_sum - 1` predictors in the final model. This model is then used to predict the cholesterol level and compared to the test data. Prediction of cholesterol levels using the elastic net model gives an MSE of `r elastic_mse`. 

## Model Comparison
```{r echo = FALSE}
resamp = resamples(list(lm = linear_fit,
                        ridge = ridge_fit,
                        lasso = lasso_fit,
                        elastic = elastic_net_fit))

resamp_summary = summary(resamp)

bwplot(resamp, metric = "RMSE", main = "RMSE comparison of 4 Models")
```

The box plot shows that the model created using the elastic net gives the lowest RMSE among the four models created for the purpose of predicting cholesterol levels. Therefore, the elastic model should be chosen when using 632 bootstrap as the cross validation method to predict cholesterol levels.

# Conclusion


